{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 00. [Dataset Load]\n",
        "---"
      ],
      "metadata": {
        "id": "XYWpKfzxD6-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ngjfsJjMjXz",
        "outputId": "28bbbfdb-6bcf-43b5-db51-0834ee017d66"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path   = '/content/drive/MyDrive/data/open.zip'\n",
        "extract_to_path = '/content/sample_data/data'\n",
        "\n",
        "os.makedirs(extract_to_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "print(\"압축 해제가 완료되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Z-7pYHrfif",
        "outputId": "8870ea71-ec63-4bb9-f5a0-2dd7060e4501"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축 해제가 완료되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 01. [Arguments]\n",
        "---"
      ],
      "metadata": {
        "id": "RoigjX5QDyst"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ZxTJ8j1fl-eH"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "\n",
        "def get_arguments():\n",
        "    parser = argparse.ArgumentParser(description=\"Speech Recognition\")\n",
        "\n",
        "    # =============== parser with data ===================== #\n",
        "    parser.add_argument('--SR', type=int, default=32000, help=\"sampling_ratio\")\n",
        "    parser.add_argument('--data_path', type=str, default='/content/sample_data/data/open', help='data_path')\n",
        "    parser.add_argument('--valid_ratio', type=float, default=0.2, help='validation data ratio')\n",
        "    # =================================================================== #\n",
        "\n",
        "    #================= parser with model ===========================#\n",
        "    parser.add_argument('--model_name', type=str, default='MLP', help='custom model name')\n",
        "    parser.add_argument('--save_dir', type=str, default='MLP_Baseline', help='custom model name')\n",
        "    parser.add_argument('--weight_name', type=str,default='checkpoint-3460',help ='model weight name')\n",
        "    parser.add_argument('--submit_name', type=str,default='baseline_submit.csv',help='submit name')\n",
        "    #=================================================================#\n",
        "\n",
        "    #================= parser with train  ===========================#\n",
        "    parser.add_argument('--learning_rate', type=float, default=3e-5, help='Learning rate')\n",
        "    parser.add_argument('--per_device_train_batch_size', type=int, default=32, help='Per device train batch size')\n",
        "    parser.add_argument('--gradient_accumulation_steps', type=int, default=4, help='Gradient accumulation steps')\n",
        "    parser.add_argument('--per_device_eval_batch_size', type=int, default=32, help='Per device eval batch size')\n",
        "    parser.add_argument('--num_train_epochs', type=int, default=10, help='Number of training epochs')\n",
        "    parser.add_argument('--warmup_ratio', type=float, default=0.1, help='Warmup ratio')\n",
        "    #=================================================================#\n",
        "\n",
        "    #================= parser with augmentation =========================#\n",
        "    parser.add_argument('--noise_prob', type=float, default=0.8, help='noise apply ratio')\n",
        "    parser.add_argument('--reduce_prob', type=float, default=0.3, help='reduce sound apply ratio')\n",
        "    parser.add_argument('--two_people_prob', type=float, default=0.5, help='two audio sum ratio')\n",
        "    parser.add_argument('--zero_people_prob', type=float, default=0.05, help='zero audio sum ratio')\n",
        "    #=================================================================#\n",
        "\n",
        "    #================= Other Arguments ================================#\n",
        "    parser.add_argument('--is_inference', type=bool, default=False, help='use only when inference')\n",
        "    parser.add_argument('--is_embedding', type=bool, default=False, help='use only when embedding')\n",
        "    parser.add_argument('--fold_iter', type=int, default=-1, help='use only when kfold')\n",
        "    #==================================================================#\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 02. [Create Class_1: Dataset Augmentation]\n",
        "---"
      ],
      "metadata": {
        "id": "1h9VXPAOdJHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "\n",
        "\n",
        "def calculate_average_length(folder_path, sampling_rate):\n",
        "    total_length = 0\n",
        "    num_files = 0\n",
        "\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith('.wav'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            audio, sr = librosa.load(file_path, sr=sampling_rate)\n",
        "            total_length += len(audio) / sr\n",
        "            num_files += 1\n",
        "\n",
        "    if num_files == 0:\n",
        "        print(f\"No .wav files found in {folder_path}.\")\n",
        "        return 0.0\n",
        "\n",
        "    average_length = total_length / num_files\n",
        "    return average_length\n",
        "\n",
        "train_folder_path = '/content/sample_data/data/open/train'\n",
        "test_folder_path = '/content/sample_data/data/open/test'\n",
        "sampling_rate = 32000\n",
        "train_average_length = calculate_average_length(train_folder_path, sampling_rate)\n",
        "print(f\"Train Dataset 평균 길이: {train_average_length:.2f} 초\")\n",
        "\n",
        "test_average_length = calculate_average_length(test_folder_path, sampling_rate)\n",
        "print(f\"Test Dataset 평균 길이: {test_average_length:.2f} 초\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sadJP6lzfBHu",
        "outputId": "37f41145-0288-43f7-d24f-eab12243549e"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset 평균 길이: 2.54 초\n",
            "Test Dataset 평균 길이: 2.54 초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AudioAugmentation:\n",
        "    def __init__(self, args, train=True):\n",
        "        self.args = args\n",
        "        self.train = train\n",
        "        self.target_length = 3  # 3초로 고정\n",
        "        if train:\n",
        "            print(\"use train augmentation (no noise)\")\n",
        "        else:\n",
        "            print(\"use validation augmentation (no noise)\")\n",
        "\n",
        "    def augmentation(self, audio, label):\n",
        "        \"\"\"\n",
        "        단일 오디오와 라벨을 입력으로 받아 증강 후 반환합니다.\n",
        "        \"\"\"\n",
        "        # 고정 길이로 조정 (3초)\n",
        "        audio = self._fix_length_to_3s(audio, self.args.SR)\n",
        "\n",
        "        # 볼륨 조절\n",
        "        audio = self._change_volume(audio)\n",
        "\n",
        "        return audio, label  # is_noise 제거\n",
        "\n",
        "    def _fix_length_to_3s(self, audio, sr):\n",
        "        \"\"\"\n",
        "        오디오를 3초로 고정.\n",
        "        - 길면 무작위로 자르고,\n",
        "        - 짧으면 앞뒤로 패딩.\n",
        "        \"\"\"\n",
        "        target_length_samples = int(self.target_length * sr)\n",
        "        current_length = len(audio)\n",
        "\n",
        "        if current_length > target_length_samples:\n",
        "            # 무작위로 자르기\n",
        "            start_idx = np.random.randint(0, current_length - target_length_samples)\n",
        "            return audio[start_idx:start_idx + target_length_samples]\n",
        "        else:\n",
        "            # 패딩 추가\n",
        "            pad_length = target_length_samples - current_length\n",
        "            pad_before = np.random.randint(0, pad_length + 1)\n",
        "            pad_after = pad_length - pad_before\n",
        "            return np.pad(audio, (pad_before, pad_after), 'constant')\n",
        "\n",
        "    def _change_volume(self, audio, volume_range=(0.5, 1.2)):\n",
        "        \"\"\"\n",
        "        볼륨을 무작위로 조절.\n",
        "        \"\"\"\n",
        "        volume_factor = np.random.uniform(volume_range[0], volume_range[1])\n",
        "        return audio * volume_factor"
      ],
      "metadata": {
        "id": "afLHvvUedI1u"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 03. [Create Class_2: FeatureExtractor] Create Melspectrogram MelSpectrogram\n",
        "---"
      ],
      "metadata": {
        "id": "M24kajIdjqMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import torchvision.transforms\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, feature_type, args):\n",
        "        self.feature_type = feature_type\n",
        "        self.args = args\n",
        "        if self.feature_type == 'spectrogram':\n",
        "            self.extractor = self._get_extract_spectrogram\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported feature type: {self.feature_type}\")\n",
        "    def _get_extract_spectrogram(self, y):\n",
        "        sr = self.args.SR\n",
        "        num_channels = 3\n",
        "        window_sizes = [25, 50, 100]\n",
        "        hop_sizes = [10, 25, 50]\n",
        "        specs = []\n",
        "        for i in range(num_channels):\n",
        "            window_length = int(round(window_sizes[i] * sr / 1000))\n",
        "            hop_length = int(round(hop_sizes[i] * sr / 1000))\n",
        "\n",
        "            y = torch.Tensor(y)\n",
        "            spec = torchaudio.transforms.MelSpectrogram(\n",
        "                sample_rate=sr, n_fft=3200, win_length=window_length, hop_length=hop_length, n_mels=128\n",
        "            )(y)\n",
        "            eps = 1e-6\n",
        "            spec = spec.numpy()\n",
        "            spec = np.log(spec + eps)\n",
        "            spec = np.asarray(torchvision.transforms.Resize((128, 250))(Image.fromarray(spec)))\n",
        "            specs.append(spec)\n",
        "        return np.array(specs)\n",
        "    def extract_features(self, y):\n",
        "        if self.feature_type == 'spectrogram':\n",
        "            return self.extractor(y)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported feature type: {self.feature_type}\")"
      ],
      "metadata": {
        "id": "-7y1CWJajq25"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 04. [Create Function_3: get_librosa_feature]feature & label extraction\n",
        "---"
      ],
      "metadata": {
        "id": "yRQDcUY2lpTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_librosa_feature(args,\n",
        "                     df:pd.DataFrame,\n",
        "                     is_train:bool):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for _, row in tqdm(df.iterrows(), desc=\"making librosa_feature...\"):\n",
        "        #load every audio file in dataframe\n",
        "\n",
        "        cur_path = os.path.join(args.data_path, row['path'])\n",
        "        y, sr = librosa.load(cur_path, sr=args.SR)\n",
        "\n",
        "        features.append(y)\n",
        "        if is_train:\n",
        "            label = row['label']\n",
        "            label_vector = np.zeros(2, dtype=np.float32)\n",
        "            label_vector[0 if label == 'fake' else 1] = 1\n",
        "            labels.append(label_vector)\n",
        "\n",
        "    if is_train:\n",
        "        return features, labels\n",
        "    return features"
      ],
      "metadata": {
        "id": "NZoy3s23lpBv"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 05. [Dataset Preprocession]\n",
        "---"
      ],
      "metadata": {
        "id": "Rqrc7OTgE7PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "# create: validation_index\n",
        "def get_validation_index(args, train_df:pd.DataFrame) -> int:\n",
        "    \"\"\"\n",
        "    Maintain consistency in dataset splitting by saving and reusing validation indices\n",
        "    \"\"\"\n",
        "\n",
        "    # original: train/valid\n",
        "    if args.fold_iter == -1:\n",
        "        num_of_validation     = int(len(train_df) * args.valid_ratio)\n",
        "        validation_index_path = f'{args.data_path}/valid_indices_{num_of_validation}'\n",
        "\n",
        "        if os.path.exists(validation_index_path):\n",
        "            validation_index = np.loadtxt(validation_index_path).astype(int)\n",
        "        else:\n",
        "            # without replacement: indices\n",
        "            validation_index  = np.random.choice(train_df.index, size=num_of_validation, replace=False).astype(int)\n",
        "            np.savetxt(validation_index_path, validation_index, delimiter=',')\n",
        "\n",
        "    # k-fold: train/valid\n",
        "    else:\n",
        "        validation_index_path = f'{args.data_path}/5kfold_valid_indices_{args.fold_iter}.csv'\n",
        "\n",
        "\n",
        "        if os.path.exists(validation_index_path):\n",
        "            validation_index = np.loadtxt(validation_index_path).astype(int)\n",
        "        else:\n",
        "            kf    = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            folds = list(kf.split(train_df))\n",
        "\n",
        "            for i in range(5):\n",
        "                traind_indices, validation_indices = folds[i]\n",
        "                validation_index_path = f'{args.data_path}/5kfold_valid_indices_{i}.csv'\n",
        "                np.savetxt(validation_index_path, validation_indices, delimiter=',')\n",
        "\n",
        "            validation_index = folds[args.fold_iter][1]\n",
        "\n",
        "\n",
        "    return validation_index"
      ],
      "metadata": {
        "id": "B-A7Da_EPIEh"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from typing import Tuple, Any\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "\n",
        "# create: train, valid, test datasets & with or without inference\n",
        "def get_dataset(args) -> Tuple[Dataset, Dataset, Dataset, Any]:\n",
        "    train_path = os.path.join(args.data_path, \"./train.csv\")\n",
        "    train_df   = pd.read_csv(train_path)\n",
        "\n",
        "    validation_index = get_validation_index(args, train_df)\n",
        "\n",
        "    valid_df = train_df.loc[validation_index]\n",
        "    train_df = train_df.drop(validation_index)\n",
        "\n",
        "    test_path = os.path.join(args.data_path, './test.csv')\n",
        "    test_df   = pd.read_csv(test_path)\n",
        "\n",
        "    print(f\"# of train: {len(train_df)}, # of valid: {len(valid_df)}\")\n",
        "\n",
        "    # use when inference\n",
        "    if args.is_inference:\n",
        "        train_dataset = None\n",
        "        valid_dataset = None\n",
        "        test_dataset  = AudioDataset(args, test_df, test=True)\n",
        "    else:\n",
        "        train_dataset = AudioDataset(args, train_df, train=True)\n",
        "        valid_dataset = AudioDataset(args, test_df, test=True)\n",
        "        test_dataset  = None\n",
        "\n",
        "    data_collactor = CustomDataCollator(args.model_name)\n",
        "\n",
        "    return (train_dataset, valid_dataset, test_dataset, data_collactor)\n",
        "\n",
        "\n",
        "# Data augmentation & Data extraction\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, args, df, train=False, validation=False, test=False):\n",
        "        self.args = args\n",
        "        self.df = df\n",
        "        self.train = train\n",
        "        self.validation = validation\n",
        "        self.test = test\n",
        "\n",
        "        # Data augmentation status\n",
        "        if self.train:\n",
        "            split = \"train\"\n",
        "            self.augmentation = AudioAugmentation(self.args, train=True)\n",
        "        elif self.validation:\n",
        "            split = \"valid\"\n",
        "            self.augmentation = AudioAugmentation(self.args, train=False)\n",
        "        elif self.test:\n",
        "            split = \"test\"\n",
        "        else:\n",
        "            raise ValueError(\"At least one of train, validation, or test must be True\")\n",
        "\n",
        "        # Data Type Conversion: Spectrogram\n",
        "        if self.args.model_name == \"resnet101\":\n",
        "            self.feature_extractor = FeatureExtractor('spectrogram', self.args)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid model name specified\")\n",
        "\n",
        "        data_path = f\"{self.args.data_path}/librosa/{split}.pkl\"\n",
        "        label_path = f\"{self.args.data_path}/librosa/{split}_label.pkl\"\n",
        "\n",
        "        # Load preprocessed data if exists, otherwise process and save\n",
        "        if os.path.exists(data_path):\n",
        "            print(f\"{split.capitalize()} dataset loaded from existing file\")\n",
        "            with open(data_path, 'rb') as reader:\n",
        "                self.librosa = pickle.load(reader)\n",
        "            if self.train or self.validation:\n",
        "                with open(label_path, 'rb') as reader:\n",
        "                    self.labels = pickle.load(reader)\n",
        "\n",
        "        # Need Preprocessing\n",
        "        else:\n",
        "            if train or validation:\n",
        "                self.librosa, self.labels = get_librosa_feature(args, df, True)\n",
        "            else:\n",
        "                self.librosa = get_librosa_feature(args, df, False)\n",
        "\n",
        "            if not os.path.exists(f\"{self.args.data_path}/librosa\"):\n",
        "                os.makedirs(f\"{self.args.data_path}/librosa\")\n",
        "\n",
        "            with open(data_path, 'wb') as writer:\n",
        "                pickle.dump(self.librosa, writer)\n",
        "            if train or validation:\n",
        "                with open(label_path, 'wb') as writer:\n",
        "                    pickle.dump(self.labels, writer)\n",
        "\n",
        "        print(f\"{split} size:\", len(self.librosa))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.librosa)\n",
        "\n",
        "    def __getitem__(self, idx) -> Tuple:\n",
        "        # Train/Validation mode\n",
        "        if self.train or self.validation:\n",
        "            data = self.librosa[idx]\n",
        "            label = self.labels[idx]\n",
        "            # Apply augmentation if in training mode\n",
        "            if self.train:\n",
        "                data = self.augmentation.augment(data)\n",
        "            # Extract features\n",
        "            data = self.feature_extractor.extract_features(data)\n",
        "            return {\"data\": data, \"label\": label}\n",
        "\n",
        "        # Test mode\n",
        "        else:\n",
        "            data = self.librosa[idx]\n",
        "            data = self.feature_extractor.extract_features(data)\n",
        "            return {\"data\": data}\n",
        "\n",
        "\n",
        "# Bundle data into batches\n",
        "class CustomDataCollator:\n",
        "    def __init__(self, model_type):\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, features):\n",
        "        # Features -> Data extraction\n",
        "        data = [torch.tensor(feature[\"data\"]) for feature in features]\n",
        "        data = torch.stack(data).to(torch.float32)\n",
        "\n",
        "        # Emotion Dataset -> Label extraction\n",
        "        if \"label\" in features[0].keys():  # train/valid\n",
        "            label = [feature[\"label\"] for feature in features]\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "        else:  # test\n",
        "            label = None\n",
        "\n",
        "        return {\"data\": data, \"label\": label}\n"
      ],
      "metadata": {
        "id": "gV8COEspIomH"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 06. [Model Design]\n",
        "---"
      ],
      "metadata": {
        "id": "cNylTCGZoXAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class DEEPCNN(nn.Module):\n",
        "    def __init__(self, args, num_classes=6, pretrained=True):\n",
        "        super(DEEPCNN, self).__init__()\n",
        "        self.model_name = args.model_name\n",
        "\n",
        "        if self.model_name == 'resnet101':\n",
        "            # ResNet101 Initialization and Fully Connected Layer Modification\n",
        "            self.model = models.resnet101(pretrained=pretrained)\n",
        "            # Set the output size to the number of emotion classes\n",
        "            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_name} is not supported.\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Softmax -> Returns the probability of each emotion class\n",
        "        output = torch.softmax(self.model(x), dim=1)  # [batch_size, num_classes]\n",
        "        return output\n",
        "\n",
        "def get_model(args):\n",
        "    \"\"\"\n",
        "    입력된 설정 값(args)에 따라 DEEPCNN 모델을 생성하고,\n",
        "    모델 정보를 출력하며 반환\n",
        "    \"\"\"\n",
        "    if args.model_name == \"resnet101\":\n",
        "        model = DEEPCNN(args)  # Create: DEEPCNN Model\n",
        "    else:\n",
        "        raise ValueError(f\"Model name {args.model_name} not found.\")\n",
        "\n",
        "    # Output: DEEPCNN Model Generation Model Structure & Total Number of Parameters\n",
        "    print(model)\n",
        "    print(f'Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "AmcPNrd4qctY"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 07. [Create Model Trainer]\n",
        "---"
      ],
      "metadata": {
        "id": "uHVo-o45rx-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple, Optional, Any, Union\n",
        "from transformers.trainer import Trainer\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "class BasicTrainer(Trainer):\n",
        "    def __init__(self, **kwds):\n",
        "        super().__init__(**kwds)\n",
        "\n",
        "        # Use CrossEntropyLoss for multi-class emotion classification\n",
        "        self.criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        # Forward pass through the model\n",
        "        output = model(inputs['data'])  # [batch_size, num_classes]\n",
        "        label = inputs['label']  # [batch_size], multi-class labels\n",
        "\n",
        "        # Compute loss\n",
        "        loss = self.criterion(output, label)\n",
        "\n",
        "        if return_outputs:\n",
        "            return loss, output, label\n",
        "        return loss\n",
        "\n",
        "    def prediction_step(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
        "        prediction_loss_only: bool,\n",
        "        ignore_keys: Optional[List[str]] = None,\n",
        "    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            eval_loss, logits, labels = self.compute_loss(model, inputs, return_outputs=True)\n",
        "\n",
        "        # Return evaluation loss, predicted logits, and ground-truth labels\n",
        "        return (eval_loss, logits, labels)"
      ],
      "metadata": {
        "id": "3RztxNzGryTK"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 08. [Create Metric] Comprehensive Analysis: Model Reliability & Classification Accuracy\n",
        "---"
      ],
      "metadata": {
        "id": "Y7qV4n7tviy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "# [Function] Expected Calibration Error\n",
        "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, strategy='uniform')\n",
        "    bin_totals = np.histogram(y_prob, bins=np.linspace(0, 1, n_bins + 1), density=False)[0]\n",
        "    non_empty_bins = bin_totals > 0\n",
        "    bin_weights = bin_totals / len(y_prob)\n",
        "    bin_weights = bin_weights[non_empty_bins]\n",
        "    prob_true = prob_true[:len(bin_weights)]\n",
        "    prob_pred = prob_pred[:len(bin_weights)]\n",
        "    ece = np.sum(bin_weights * np.abs(prob_true - prob_pred))\n",
        "    return ece\n",
        "\n",
        "# [Function] AUC, Brier Score, ECE\n",
        "def auc_brier_ece_emotions(answer_array: np.array, pred_array: np.array) -> Dict:\n",
        "    \"\"\"\n",
        "    - answer_array: Ground truth 정답 레이블 (one-hot encoded 형태) [batch_size, num_classes]\n",
        "    - pred_array: 예측 확률값 [batch_size, num_classes]\n",
        "    \"\"\"\n",
        "    n_classes = answer_array.shape[1]  # 감정 클래스 수 (6개)\n",
        "    auc_scores = []\n",
        "    brier_scores = []\n",
        "    ece_scores = []\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        # Calculate: AUC\n",
        "        auc_score = roc_auc_score(answer_array[:, i], pred_array[:, i])\n",
        "        auc_scores.append(auc_score)\n",
        "\n",
        "        # Calculate: Brier Score\n",
        "        brier_score = mean_squared_error(answer_array[:, i], pred_array[:, i])\n",
        "        brier_scores.append(brier_score)\n",
        "\n",
        "        # Calculate: Expected Calibration Error\n",
        "        ece_score = expected_calibration_error(answer_array[:, i], pred_array[:, i])\n",
        "        ece_scores.append(ece_score)\n",
        "\n",
        "    # Calculate: Average for each metric\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    mean_brier = np.mean(brier_scores)\n",
        "    mean_ece = np.mean(ece_scores)\n",
        "\n",
        "    # Calculate: Custom Score\n",
        "    combined_score = 0.5 * (1 - mean_auc) + 0.25 * mean_brier + 0.25 * mean_ece\n",
        "\n",
        "    # Return: Result dictionary\n",
        "    metrics = {\n",
        "        \"auc_scores\": auc_scores,  # 각 클래스별 AUC\n",
        "        \"mean_auc\": mean_auc,      # 평균 AUC\n",
        "        \"brier_scores\": brier_scores,  # 각 클래스별 Brier Score\n",
        "        \"mean_brier\": mean_brier,      # 평균 Brier Score\n",
        "        \"ece_scores\": ece_scores,  # 각 클래스별 ECE\n",
        "        \"mean_ece\": mean_ece,      # 평균 ECE\n",
        "        \"combined_score\": combined_score\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "7ZNDjO0RvjLJ"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 출력값을 추적하기 위한 변수\n",
        "previous_metrics = None\n",
        "\n",
        "# 새로운 메트릭 계산 및 출력 함수\n",
        "def compute_and_output_metrics(args, answer_array, pred_array):\n",
        "    global previous_metrics\n",
        "    current_metrics = auc_brier_ece_emotions(answer_array, pred_array)\n",
        "\n",
        "    # 이전 메트릭과 비교하여 변경된 경우에만 출력 및 저장\n",
        "    if previous_metrics is None or not np.allclose(list(previous_metrics.values()), list(current_metrics.values())):\n",
        "        # 화면에 출력\n",
        "        print(\"===== Validation Metrics ===============\")\n",
        "        for key, value in current_metrics.items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        print(\"=========================================\")\n",
        "\n",
        "        # CSV 파일로 저장\n",
        "        metrics_df = pd.DataFrame(current_metrics)\n",
        "        metrics_path = f\"{args.data_path}/metrics.csv\"\n",
        "        metrics_df.to_csv(metrics_path, index=False)\n",
        "        print(\"Metrics saved to 'metrics.csv'\")\n",
        "\n",
        "        # 이전 메트릭 업데이트\n",
        "        previous_metrics = current_metrics\n",
        "    else:\n",
        "        print(\"Metrics have not changed. Skipping output and save.\")"
      ],
      "metadata": {
        "id": "85acXQKz2vop"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 09. [Model Train]\n",
        "---"
      ],
      "metadata": {
        "id": "HCmkdW2swYAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = dict()\n",
        "    pred = eval_preds.predictions.copy()\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    label = eval_preds.label_ids.copy()\n",
        "    accuracy = np.sum(pred == label) / len(pred)\n",
        "    metric['accuracy'] = accuracy\n",
        "    additional_metric = auc_brier_ece_emotions(eval_preds.label_ids, eval_preds.predictions)\n",
        "    metric.update(additional_metric)\n",
        "    print(\"===== Validation Example ===============\")\n",
        "    sample_idx = np.random.randint(0, len(eval_preds.label_ids), 5)\n",
        "    for idx in sample_idx:\n",
        "        print(f\"Sample {idx}\")\n",
        "        print(f\"True Label: {eval_preds.label_ids[idx]}\")\n",
        "        print(f\"Prediction: {eval_preds.predictions[idx]}\\n\")\n",
        "    print(\"=======================================\")\n",
        "    return metric\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    model = get_model(args)\n",
        "    train_ds, valid_ds, _, data_collator = get_dataset(args)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./model/{args.save_dir}\",\n",
        "        evaluation_strategy='epoch',\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=args.learning_rate,\n",
        "        per_device_train_batch_size=args.per_device_train_batch_size,\n",
        "        gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
        "        per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
        "        num_train_epochs=args.num_train_epochs,\n",
        "        warmup_ratio=args.warmup_ratio,\n",
        "        logging_steps=30,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"combined_score\",\n",
        "        save_total_limit=8,\n",
        "        remove_unused_columns=False,\n",
        "        dataloader_num_workers=8,\n",
        "        greater_is_better=False,\n",
        "    )\n",
        "    trainer = BasicTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=valid_ds,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    print(args)\n",
        "    trainer.train()\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = get_arguments()\n",
        "    main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "4n33EvpEx929",
        "outputId": "3c5d16c7-dce8-418c-b88b-253ef5dd97e5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--SR SR] [--data_path DATA_PATH] [--valid_ratio VALID_RATIO]\n",
            "                                [--model_name MODEL_NAME] [--save_dir SAVE_DIR]\n",
            "                                [--weight_name WEIGHT_NAME] [--submit_name SUBMIT_NAME]\n",
            "                                [--learning_rate LEARNING_RATE]\n",
            "                                [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                                [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                                [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                [--warmup_ratio WARMUP_RATIO] [--noise_prob NOISE_PROB]\n",
            "                                [--reduce_prob REDUCE_PROB] [--two_people_prob TWO_PEOPLE_PROB]\n",
            "                                [--zero_people_prob ZERO_PEOPLE_PROB]\n",
            "                                [--is_inference IS_INFERENCE] [--is_embedding IS_EMBEDDING]\n",
            "                                [--fold_iter FOLD_ITER]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-b3326237-86cd-4b09-97e9-79b27a3ba652.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 10. [inference]\n",
        "---"
      ],
      "metadata": {
        "id": "dbpZKHy5zLu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from safetensors.torch import load_model\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def main(args):\n",
        "    model = get_model(args)\n",
        "    load_model(model, f\"./model/{args.save_dir}/{args.weight_name}/model.safetensors\")\n",
        "\n",
        "    _, _, test_ds, data_collator = get_dataset(args)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_ds,\n",
        "                                                  batch_size=args.per_device_eval_batch_size,\n",
        "                                                  collate_fn=data_collator,\n",
        "                                                  drop_last=False,\n",
        "                                                  shuffle=False)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for features in tqdm(iter(test_dataloader)):\n",
        "            data = features['data'].to(device)\n",
        "            probs = model(data)  # [batch_size, num_classes]\n",
        "            probs = probs.cpu().detach().numpy().astype(np.float32)\n",
        "            predictions.extend(probs.tolist())\n",
        "\n",
        "    submit = pd.read_csv(f'{args.data_path}/sample_submission.csv')\n",
        "    submit = submit.astype({\n",
        "        'id': 'object',\n",
        "        'angry': 'float32',\n",
        "        'fear': 'float32',\n",
        "        'sad': 'float32',\n",
        "        'disgust': 'float32',\n",
        "        'neutral': 'float32',\n",
        "        'happy': 'float32'\n",
        "    })\n",
        "\n",
        "    submit.iloc[:, 1:] = predictions\n",
        "    submit.head()\n",
        "\n",
        "    print(\"=============== Prediction Example ===============\")\n",
        "    print(predictions[:10])\n",
        "    print(\"==================================================\")\n",
        "\n",
        "    submit.to_csv(f'./submit/{args.submit_name}', index=False)\n",
        "    print(f\"Submission saved to ./submit/{args.submit_name}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = get_arguments()\n",
        "    main(args)\n"
      ],
      "metadata": {
        "id": "FxbBzj1xzMY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}